{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9823f812",
   "metadata": {},
   "source": [
    "# ðŸš€ FlexAI Compute Selection\n",
    "\n",
    "Use this notebook to select your GPU/CPU configuration before running ML workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349598f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FlexAI GPU Selector Widget\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/.flexai')\n",
    "\n",
    "from flexai_widget import show_gpu_selector\n",
    "\n",
    "# Display the GPU selection UI\n",
    "show_gpu_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad213688",
   "metadata": {},
   "source": [
    "## Available GPU Types\n",
    "\n",
    "The mock FlexAI API provides the following GPU types:\n",
    "\n",
    "- **NVIDIA T4** - 16GB VRAM - $0.35/hr\n",
    "- **NVIDIA V100** - 32GB VRAM - $2.48/hr\n",
    "- **NVIDIA A100-40GB** - 40GB VRAM - $3.09/hr\n",
    "- **NVIDIA A100-80GB** - 80GB VRAM - $3.67/hr\n",
    "- **NVIDIA H100** - 80GB VRAM - $4.76/hr\n",
    "- **NVIDIA L4** - 24GB VRAM - $0.61/hr\n",
    "\n",
    "Click on any option above to provision that GPU type for your notebook session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36846d80",
   "metadata": {},
   "source": [
    "## Check Current GPU Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what GPU is currently provisioned\n",
    "import httpx\n",
    "\n",
    "async def check_gpu_status():\n",
    "    try:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get('http://backend:8000/api/compute/instances')\n",
    "            instances = response.json()\n",
    "            \n",
    "            if instances:\n",
    "                for inst in instances:\n",
    "                    print(f\"âœ“ Active GPU: {inst.get('gpu_type', 'Unknown')}\")\n",
    "                    print(f\"  Instance ID: {inst.get('id')}\")\n",
    "                    print(f\"  Status: {inst.get('status')}\")\n",
    "            else:\n",
    "                print(\"No GPU currently provisioned - using CPU\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking status: {e}\")\n",
    "\n",
    "import asyncio\n",
    "await check_gpu_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86623340",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After selecting your GPU, you can:\n",
    "\n",
    "1. Open [test_ml_environment.ipynb](test_ml_environment.ipynb) to test ML libraries\n",
    "2. Open [pytorch_image_classification.ipynb](pytorch_image_classification.ipynb) for PyTorch examples  \n",
    "3. Create your own notebook and start training models!\n",
    "\n",
    "The selected GPU will be available for all notebooks in this session."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
