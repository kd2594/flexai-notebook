# ğŸ­ FlexAI Notebook - Local Mock Mode Setup

## Overview

This is a **fully local, mock version** of the FlexAI Notebook Platform that runs WITHOUT requiring any real FlexAI credentials or external services. Perfect for local development and testing!

## ğŸŒŸ What's Included

This local setup includes:

âœ… **Mock FlexAI API Server** - Simulates FlexAI compute platform locally  
âœ… **PostgreSQL Database** - Open-source database for session persistence  
âœ… **Redis Cache** - Open-source in-memory data store  
âœ… **Jupyter Notebook** - Full Jupyter environment with JupyterLab  
âœ… **Backend API** - FastAPI server connecting all components  
âœ… **Pre-configured Everything** - No manual configuration needed!

## ğŸš€ Quick Start

### Prerequisites

- Docker Desktop (or Docker + Docker Compose)
- macOS, Linux, or Windows with WSL2

### Step 1: Start the Platform

```bash
cd flexai-notebook
./start.sh
```

That's it! Everything is pre-configured with dummy values.

### Step 2: Access the Services

Once started, access:

- **Jupyter Notebook**: http://localhost:8888
  - Token: `local_demo_token_secure_123`
  
- **Backend API**: http://localhost:8000
  - Docs: http://localhost:8000/docs
  
- **Mock FlexAI API**: http://localhost:9000
  - Docs: http://localhost:9000/docs

### Step 3: Test It Out

1. Open Jupyter at http://localhost:8888
2. Use token: `local_demo_token_secure_123`
3. Open the getting started notebook
4. Click the "Select GPU" button
5. Choose a GPU type (all are mocked)
6. Run your code!

## ğŸ“¦ What's Running

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Jupyter Notebook (localhost:8888)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend API (localhost:8000)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mock FlexAI API (localhost:9000)       â”‚
â”‚  PostgreSQL (localhost:5432)            â”‚
â”‚  Redis (localhost:6379)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

All configuration is in the `.env` file with dummy values:

```env
# Mock FlexAI credentials (not real!)
FLEXAI_API_KEY=mock_api_key_12345_local_testing_only
FLEXAI_API_URL=http://mock-flexai:9000
FLEXAI_ORG_ID=mock_org_local_demo_001

# Jupyter access
JUPYTER_TOKEN=local_demo_token_secure_123

# Database (PostgreSQL running locally)
DATABASE_URL=postgresql://flexai_user:flexai_password_local@postgres:5432/flexai_notebook_db

# Redis (running locally)
REDIS_URL=redis://redis:6379
```

## ğŸ® Available Mock GPUs

The mock FlexAI API provides these simulated GPU types:

- **NVIDIA T4** - 16GB, $0.50/hr
- **NVIDIA V100** - 32GB, $2.00/hr
- **NVIDIA A100 40GB** - 40GB, $3.50/hr
- **NVIDIA A100 80GB** - 80GB, $4.50/hr
- **NVIDIA H100** - 80GB, $5.00/hr
- **NVIDIA L4** - 24GB, $1.00/hr

## ğŸ”„ Switching to Production

When you're ready to connect to real FlexAI:

1. **Get your FlexAI credentials** from the FlexAI platform
2. **Update `.env` file**:
   ```env
   MOCK_MODE=false
   FLEXAI_API_KEY=your_real_api_key
   FLEXAI_API_URL=https://api.flexai.com
   FLEXAI_ORG_ID=your_real_org_id
   ```
3. **Restart the platform**:
   ```bash
   ./stop.sh
   ./start.sh
   ```

## ğŸ› ï¸ Development Commands

```bash
# Start all services
./start.sh

# Stop all services
./stop.sh

# View logs
docker-compose logs -f

# View specific service logs
docker-compose logs -f backend
docker-compose logs -f jupyter
docker-compose logs -f mock-flexai

# Restart a service
docker-compose restart backend

# Access database
docker-compose exec postgres psql -U flexai_user -d flexai_notebook_db

# Access Redis CLI
docker-compose exec redis redis-cli
```

## ğŸ“Š Testing the Mock API Directly

You can test the mock FlexAI API directly:

```bash
# Get available GPUs
curl http://localhost:9000/v1/compute/gpu-types \
  -H "Authorization: Bearer mock_key"

# Create an instance
curl -X POST http://localhost:9000/v1/compute/instances \
  -H "Authorization: Bearer mock_key" \
  -H "Content-Type: application/json" \
  -d '{
    "gpu_type": "nvidia-a100-40gb",
    "gpu_count": 1,
    "cpu_cores": 8,
    "ram_gb": 32
  }'
```

## ğŸ› Troubleshooting

### Services won't start

```bash
# Clean up and rebuild
docker-compose down -v
docker-compose up --build
```

### Can't access Jupyter

1. Check if service is running: `docker-compose ps`
2. Check logs: `docker-compose logs jupyter`
3. Make sure port 8888 is not in use

### Database connection issues

```bash
# Restart PostgreSQL
docker-compose restart postgres

# Check if it's healthy
docker-compose ps postgres
```

## ğŸ“ Project Structure

```
flexai-notebook/
â”œâ”€â”€ .env                    # Local configuration (dummy values)
â”œâ”€â”€ docker-compose.yml      # All services defined here
â”œâ”€â”€ start.sh                # Start script
â”œâ”€â”€ stop.sh                 # Stop script
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py            # FastAPI backend
â”‚   â”œâ”€â”€ flexai_client.py   # FlexAI API client
â”‚   â”œâ”€â”€ mock_flexai_server.py  # Mock FlexAI API
â”‚   â””â”€â”€ session_manager.py
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.jupyter
â”‚   â”œâ”€â”€ Dockerfile.mock-flexai
â”‚   â””â”€â”€ init-db.sql        # Database initialization
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ extension/         # Jupyter custom extensions
â””â”€â”€ notebooks/
    â””â”€â”€ getting_started.ipynb
```

## ğŸ¯ What's Different from Production?

| Feature | Mock Mode | Production Mode |
|---------|-----------|----------------|
| FlexAI API | Local mock server | Real FlexAI cloud |
| GPU Provisioning | Instant (simulated) | Real provisioning |
| Actual GPU | Simulated | Real GPU hardware |
| Costs | Free (local) | Real costs apply |
| Internet Required | No | Yes |

## ğŸ’¡ Tips

1. **No real credentials needed** - All values in `.env` are dummy/mock
2. **Everything runs locally** - No internet connection to external services
3. **Safe to experiment** - Nothing affects real infrastructure
4. **Perfect for demos** - Show the UI/UX without costs
5. **Easy handoff** - FlexAI team just needs to swap the API URL

## ğŸ¤ Handing Off to FlexAI Team

Share this with your FlexAI team:

1. "This is a fully working local demo"
2. "To connect to real FlexAI, just update these 3 values in `.env`:"
   - `FLEXAI_API_KEY`
   - `FLEXAI_API_URL`
   - `FLEXAI_ORG_ID`
3. "Set `MOCK_MODE=false` in `.env`"
4. "Everything else stays the same!"

## ğŸ“ Next Steps

1. âœ… Everything is set up and ready to run
2. âœ… Start with `./start.sh`
3. âœ… Test the interface
4. âœ… When ready, get real FlexAI credentials
5. âœ… Update `.env` and set `MOCK_MODE=false`

---

**Questions?** Check the logs:
```bash
docker-compose logs -f
```
